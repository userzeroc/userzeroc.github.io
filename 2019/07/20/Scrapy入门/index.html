<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <meta name="keywords" content="hexo, autumn">
    <title>
        初见
    </title>
    <!-- favicon -->
    
    <link rel="icon" href="https://cdn.jsdelivr.net/gh/frontendsophie/hexo-theme-autumn@1.0.0/source/img/favicon.ico">
    
    <link rel="stylesheet" href="/css/style.css">

    <!-- highlight -->
    <link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.12.0/styles/github-gist.min.css">
    <script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script>
    <script>
        hljs.initHighlightingOnLoad()
    </script>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/frontendsophie/hexo-infinite-scroll@1.0.0/dist/hexo-infinite-scroll.min.css">
    <script src="https://cdn.jsdelivr.net/gh/frontendsophie/hexo-infinite-scroll@1.0.0/dist/hexo-infinite-scroll.min.js"></script>
    <script>
        infiniteScroll()

        // for mobile menu
        $(function () {
            $('.social-button').click(function () {
                if ($('.social-links').hasClass('hide-links')) {
                    $('.social-links').removeClass('hide-links')
                } else {
                    $('.social-links').addClass('hide-links')
                }
            })
        })
    </script>
</head>

    <body style="background: url(https://cdn.jsdelivr.net/gh/frontendsophie/hexo-theme-autumn@1.0.0/source/img/button-bg.png) #f3f3f3">
        <div class="container">
            <header class="header">
    <h1 class="title">
        <a href="/" class="logo">
            初见
        </a>
    </h1>
    <h2 class="desc">
        
    </h2>

    <nav class="links">
        <button class="social-button">
            menu
        </button>
        <ul class="social-links hide-links">
            
                <li>
                    <a href="https://github.com/FrontendSophie">
                        Github
                    </a>
                </li>
                
                <li>
                    <a href="https://www.linkedin.com/in/frontendsophie/">
                        LinkedIn
                    </a>
                </li>
                
        </ul>
    </nav>
</header>
                <main class="main">
                    <article class="post">
    
    
    <h4 class="post-cat">
        <a href="/categories/Python/">
            Python
        </a>
    </h4>
    
    
    <h2 class="post-title">
        Scrapy入门
    </h2>
    <ul class="post-date">
        <li>
            2019-07-20
        </li>
        <li>
            John Doe
        </li>
    </ul>
    <div class="post-content">
        <h2 id="本节任务"><a href="#本节任务" class="headerlink" title="本节任务"></a>本节任务</h2><ol>
<li>创建一个Scrapy项目</li>
<li>写第一个爬虫进行数据抓取</li>
<li>使用命令导出抓取数据</li>
<li>将spider改为递归跟踪链接</li>
<li>使用爬虫参数</li>
</ol>
<h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#新建项目</span></span><br><span class="line">scrapy startproject tutorial</span><br><span class="line"><span class="comment">#使用模板新建爬虫</span></span><br><span class="line">scrapy genspider 爬虫名 起始链接</span><br></pre></td></tr></table></figure>

<p>在工程下创建一个名为 <strong>tutorial</strong>的项目将包含以下目录</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tutorial/</span><br><span class="line">    scrapy.cfg            <span class="comment"># deploy configuration file</span></span><br><span class="line"></span><br><span class="line">    tutorial/             <span class="comment"># project's Python module, you'll import your code from here</span></span><br><span class="line">        __init__.py</span><br><span class="line"></span><br><span class="line">        items.py          <span class="comment"># project items definition file</span></span><br><span class="line"></span><br><span class="line">        middlewares.py    <span class="comment"># project middlewares file</span></span><br><span class="line"></span><br><span class="line">        pipelines.py      <span class="comment"># project pipelines file</span></span><br><span class="line"></span><br><span class="line">        settings.py       <span class="comment"># project settings file</span></span><br><span class="line"></span><br><span class="line">        spiders/          <span class="comment"># a directory where you'll later put your spiders</span></span><br><span class="line">            __init__.py</span><br></pre></td></tr></table></figure>

<h1 id="第一个爬虫"><a href="#第一个爬虫" class="headerlink" title="第一个爬虫"></a>第一个爬虫</h1><ol>
<li>定义爬虫类</li>
<li>爬虫类需为<strong>scrapy.Spider</strong>的子类</li>
<li>将爬虫保存在<strong>spider</strong>目录下</li>
<li>爬虫是用来解析下载内容以及提取数据的代码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Saved file %s'</span> % filename)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p><strong>一些方法的解释</strong></p>
<ul>
<li>name：爬虫的名字</li>
<li>start_request：必须返回一个Itable of requests,从中开始爬取，随后的请求从这些初始请求中依次生成。</li>
<li>parse：解析器，将调用方法，解析响应，抓取数据提取为dict，并查找新的url以跟踪和创建请求。被用来调用处理这些url的每个请求，pares是scrapy默认的回调方法。</li>
</ul>
<p><strong>运行爬虫</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy cralw quotes</span><br></pre></td></tr></table></figure>

<p>此命令将运行名为quotes的爬虫</p>
<p><strong>启动请求的快捷方法</strong></p>
<p>start_request()生成的方法scrapy.Request来自url的对象，只需定义start_url的具有列表的类属性。然后列表将由start_requests()为爬虫创建初始请求</p>
<p><strong>提取响应中的数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).get(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).get(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).getall(),</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>

<p><strong>提取数据的存储</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#json格式</span></span><br><span class="line">scrapy crawl quotes -o quotes.json</span><br><span class="line"><span class="comment">#JSonline格式</span></span><br><span class="line">scrapy crawl quotes -o quotes.jl</span><br></pre></td></tr></table></figure>

<blockquote>
<p>JSonline简介<br>类似于流，可以很容易的向其中附加新的记录</p>
</blockquote>
<p><strong>下一个链接</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            next_page = next_page.urljoin(next_page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page,callback=self.parse)</span><br></pre></td></tr></table></figure>

<p>在一页数据提取之后，parse()方法查找下一页的链接，并使用urljoin()方法，生成下一页新的请求，将自身注册为回调，用以处理下一页的数据提取，并保持在所有页中进行。</p>
<p><strong>创建请求的快捷方式</strong><br><em>response.follow</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).get()</span><br><span class="line">       <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">           <span class="keyword">yield</span> response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>

<p>response.follow直接支持相对url，无需调用urljion。response只返回一个请求实例，仍需要生成这个请求。</p>
<p>也可以将选择器传给response.follow,这个选择器必须应提取必要的属性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> herf <span class="keyword">in</span> response.css(<span class="string">'li.next a'</span>):</span><br><span class="line">    <span class="keyword">yield</span> response.follow(a,callback=self.parse)</span><br></pre></td></tr></table></figure>


    </div>
</article>
                </main>
                <aside class="aside">
                    <section class="aside-section">
                        
    <h1>Categories</h1>

    <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/生活/">生活</a></li></ul>

                    </section>
                    <section class="aside-section">
                        
    <h1>Archives</h1>

    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a></li></ul>


                    </section>
                    <section class="aside-section tag">
                        
    <h1>Tags</h1>

    <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/技术/">技术</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/随笔/">随笔</a></li></ul>

                    </section>
                </aside>
        </div>
    </body>

</html>